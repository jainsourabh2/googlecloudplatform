# Running Spark Job using a Java JAR from console.
./bin/spark-submit \
  --class com.example.spark.JavaSparkApp \
  --master local \
  /home/admin_sourabhsjain_altostrat_com/application/dream11-spark-kafka/target/dataproc-templates-1.0-SNAPSHOT-jar-with-dependencies.jar

# Calculate the size of the message.
https://www.javainuse.com/bytesizejson

# Find process running on a PORT in Linuc
netstat -ano | find "PORT_NUMBER" | find "LISTEN"

# Find BigQuery JSON Schema from command line
bq show --schema --format=prettyjson myprojectid:mydataset.mytable > /tmp/myschema.json

# AWS GCP VM comparison
GCP : https://gcloud-compute.com/amd.html
AWS : https://instances.vantage.sh/

#Create a GKE Cluster
gcloud container clusters create-auto hello-cluster --region=us-central1

gcloud projects list --filter="project_number=945591414910"

#Log into the pod.
kubectl exec -n <name space here> <pod-name>  -it -- /bin/sh

#Find process on a specific port
lsof -n -i :80 | grep LISTEN
