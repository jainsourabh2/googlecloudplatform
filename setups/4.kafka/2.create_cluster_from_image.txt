# Create broker 1

gcloud beta compute instances create kafka-broker-01 \
    --source-machine-image kafka-machine-image  \
    --zone ${region_zone_a} \
    --machine-type ${kafka_machine_type} \
    --private-network-ip 10.65.0.13 \
    --subnet ${vpc_subnet} \
    --tags kafka \
    --labels=application=kafka \
    --no-address 

# Create broker 2

gcloud beta compute instances create kafka-broker-02 \
    --source-machine-image kafka-machine-image  \
    --zone ${region_zone_b} \
    --machine-type ${kafka_machine_type} \
    --private-network-ip 10.65.0.14 \
    --subnet ${vpc_subnet} \
    --tags kafka \
    --labels=application=kafka \
    --no-address

    
# Create broker 3

  gcloud beta compute instances create kafka-broker-03 \
    --source-machine-image kafka-machine-image  \
    --zone ${region_zone_c} \
    --machine-type ${kafka_machine_type} \
    --private-network-ip 10.65.0.15 \
    --subnet ${vpc_subnet} \
    --tags kafka \
    --labels=application=kafka \
    --no-address 

gcloud beta compute ssh kafka-broker-01 --tunnel-through-iap --zone=${region_zone_a}
gcloud beta compute ssh kafka-broker-02 --tunnel-through-iap --zone=${region_zone_b}
gcloud beta compute ssh kafka-broker-03 --tunnel-through-iap --zone=${region_zone_c}

## Repeat below for all the above 3 machines and change the broker.id and IP address.
#############################################
su -l kafka

sudo vim /opt/kafka/config/server.properties

#Change the broker id 
broker.id=0
#Change the internal IP
listeners=PLAINTEXT://10.65.0.13:9092
advertised.listeners=PLAINTEXT://10.65.0.13:9092
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=2147483647
log.dirs=/data/kafka/logs/
num.partitions=5
log.retention.hours=6
log.segment.bytes=2147483647
log.retention.check.interval.ms=300000

############################# Zookeeper #############################
zookeeper.connect=zk-01.us-east4-a.c.on-prem-project-337210.internal:2181,zk-02.us-east4-b.c.on-prem-project-337210.internal:2181,zk-03.us-east4-c.c.on-prem-project-337210.internal:2181
# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=6000

#######################################################
group.initial.rebalance.delay.ms=0
message.max.bytes=2147483647
max.message.bytes=2147483647
reserved.broker.max.id=10000000
auto.leader.rebalance.enable=true
delete.topic.enable=true
default.replication.factor=3
replica.lag.time.max.ms=100000
replica.fetch.wait.max.ms=5000
queued.max.requests=8192
num.replica.fetchers=6
num.network.threads=16
num.recovery.threads.per.data.dir=3
num.io.threads=16
replica.socket.receive.buffer.bytes=2147483647
replica.fetch.max.bytes=2147483647
message.timestamp.type=LogAppendTime
group.max.session.timeout.ms=7200000

##End
#############################################


gcloud beta compute ssh kafka-broker-01 \
    --tunnel-through-iap \
    --zone=${region_zone_a} \
    --command 'sudo rm -rf /data/kafka/logs/ && sudo systemctl enable kafka.service && sudo systemctl start kafka.service'
    
gcloud beta compute ssh kafka-broker-02 \
    --tunnel-through-iap \
    --zone=${region_zone_b} \
    --command  'sudo rm -rf /data/kafka/logs/ && sudo systemctl enable kafka.service && sudo systemctl start kafka.service'
    
gcloud beta compute ssh kafka-broker-03 \
    --tunnel-through-iap \
    --zone=${region_zone_c} \
    --command  'sudo rm -rf /data/kafka/logs/ && sudo systemctl enable kafka.service && sudo systemctl start kafka.service'
